# -*- coding: utf-8 -*-
"""project1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dpvc0pbGebmOKiMGcO0-qn5rjL40mRmE
"""



"""
*   Data cleaning
*   EDA
*   Feature Engineering
*   Model Selection
*   Choosing the appropriate loss metric
*   Hyperparameter tuning"""



"""#Day 1

Problem Statement-
We have customers data , we are trying to predict whether to give loan or not
"""

# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score
from scipy.stats import chi2_contingency
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support
import warnings
import os

a1=pd.read_excel('/content/drive/MyDrive/case_study1.xlsx')
a2=pd.read_excel('/content/drive/MyDrive/case_study2.xlsx')

df1=a1.copy()
df2=a2.copy()

df1

df2

df1.info()

df2.info()

"""

*  Data science(Ml,NLP,AI model developer)
*   Mlops(deployement team)
*   Data engineer(ETL-data extract)
*   Business team
*   Distribution team(Sales team)"""

#Remove null (As there is only 40 values)
# Remove nulls
df1 = df1.loc[df1['Age_Oldest_TL'] != -99999]

df1.shape

columns_to_be_removed=[]
for i in df2.columns:
  if df2.loc[df2[i]==-99999].shape[0]>10000:
    columns_to_be_removed.append(i)

columns_to_be_removed

df2=df2.drop(columns=columns_to_be_removed,axis=1)

df2.shape

for i in df2.columns:
  df2=df2.loc[df2[i]!=-99999]

df2.shape

df2.isna().sum()

df1.isna().sum()

#Checking the same columns names to merge
for i in list(df1.columns):
  for j in list(df2.columns):
    if i==j:
      print(i)

#Now join both the tables
df=pd.merge(df1,df2,how='inner',left_on=['PROSPECTID'],right_on=['PROSPECTID'])

df

df.shape

df.isna().sum().sum()

"""Now we will divide the features into-
*   Categorical
*   Numerical


---

And then Treat them sepretly


"""

#Check how many columns are categorical
for i in df.columns:
  if df[i].dtype=='object':
    print(i)

df['MARITALSTATUS'].value_counts()

"""
Now we will see how to deel with the categorical data<br>
If the data is in ordinal state like best,good worse then we can give 3,2,1 but if data is nominal form then we will use -<br>**CHISQUARE TEST** - First make contigency table<br>
Hypothesis testing<br>
Like Are these two associated -- Maritalstatus and Approved_Flag?
*   H0:Null hypothesis<br>
      Not associated
*   H1:Alternate hypothesis<br>Associated
*   Alpha is always assumed which is 5%
*Confidence interval =1-alpha
*   Now calculate the evidence against H0 which is p-value
*   p-value is calculated using test T-test,Chisquare,Anova<br>Degree of freedom
*p-value <=alpha:<br>
Reject H0<br>
if p-value>alpha<br>
failed to reject H0
# ***Very Important***
*Chi-square = categorical vs categorical
*T-test = categorical vs numerical(2 category)
*Anova = categorical vs numerical(>=3 category)




"""

#We will use chi-square test here as all the columns are categorical to approved states which is also categorical
for i in ['MARITALSTATUS','EDUCATION','GENDER','last_prod_enq2','first_prod_enq2']:
  chi2,pval, _, _=chi2_contingency(pd.crosstab(df[i],df['Approved_Flag']))
  print(i,chi2,pval)

"""Since all the categorical features have pval<0.05,we will accept all."""

numeric_cols=[]
for i in df.columns:
  if df[i].dtype!='object' and i not in ['Approved_Flag']:
    numeric_cols.append(i)

numeric_cols

"""Multicollinearity vs Coorelation


*   Multicollinerity = Predictability of each feature by other features
*   coorelation = Coorelation is specific to linear relationships between features(Always used for linar relations butween two columns,In convex funtions coorelation gives misleading values)


---
for multicollinerity we measure VIF<br>Variation inflation Function<br>
vif=1/1-R^2
*   VIF ranges from 1 to infinity
*   VIF=1 :No multicollinearity
*   VIF between 1 and 5 : Low multicollinearity
*   VIF between 5 and 10 : Moderate multicollinearity
*VIF above 10: High multicollinearity





"""

#VIF sequential cheak up
vif_data=df[numeric_cols]
total_columns=vif_data.shape[1]
columns_to_kept=[]
column_index=0

for i in range(0,total_columns):
  vif_value=variance_inflation_factor(vif_data.values,column_index)
  print(column_index,'---',vif_value)
  if vif_value<=6:
    columns_to_kept.append(vif_data.columns[column_index])
    column_index=column_index+1
  else:
    vif_data=vif_data.drop(columns=vif_data.columns[column_index])

columns_to_kept

#Check Anova for columns_to_be_kept
from scipy.stats import f_oneway
columns_to_kept_numerical=[]

for i in columns_to_kept:
  a=list(df[i])
  b=list(df['Approved_Flag'])

  group_P1=[value for value,group in zip(a,b) if group=='P1']
  group_P2=[value for value,group in zip(a,b) if group=='P2']
  group_P3=[value for value,group in zip(a,b) if group=='P3']
  group_P4=[value for value,group in zip(a,b) if group=='P4']

  f_statistic,p_value=f_oneway(group_P1,group_P2,group_P3,group_P4)
  if p_value<=0.05:
    columns_to_kept_numerical.append(i)

columns_to_kept_numerical

features=columns_to_kept_numerical+['MARITALSTATUS','EDUCATION','GENDER','last_prod_enq2','first_prod_enq2']
df=df[features+['Approved_Flag']]

df['MARITALSTATUS'].unique()

df['EDUCATION'].unique()

df['GENDER'].unique()

df['last_prod_enq2'].unique()

df['first_prod_enq2'].unique()

#LIKE we are assining here
#Ordinal features--EDUCATION
#SSC-1
#12th-2
#Gradguate-3
#Post-Graduate-4
#Others-1
#Professional-3
df.loc[df['EDUCATION']=='SSC',['EDUCATION']]=1
df.loc[df['EDUCATION']=='12TH',['EDUCATION']]=2
df.loc[df['EDUCATION']=='GRADUATE',['EDUCATION']]=3
df.loc[df['EDUCATION']=='POST-GRADUATE',['EDUCATION']]=4
df.loc[df['EDUCATION']=='UNDER GRADUATE',['EDUCATION']]=3
df.loc[df['EDUCATION']=='OTHERS',['EDUCATION']]=1
df.loc[df['EDUCATION']=='PROFESSIONAL',['EDUCATION']]=3

df['EDUCATION'].unique()

df['EDUCATION'].value_counts()

df['EDUCATION']=df['EDUCATION'].astype(int)

df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS', 'GENDER', 'last_prod_enq2', 'first_prod_enq2'])

# Convert only boolean columns (from one-hot) to integers
bool_cols = df_encoded.select_dtypes(include='bool').columns
df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)

df_encoded

df_encoded.info()

"""Data preprocessing"""

y=df_encoded['Approved_Flag']
x=df_encoded.drop(['Approved_Flag'],axis=1)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

#Random Forest
from sklearn.ensemble import RandomForestClassifier
rf_classifier=RandomForestClassifier(n_estimators=200,random_state=42)
rf_classifier.fit(x_train,y_train)
y_pred=rf_classifier.predict(x_test)

from sklearn.model_selection import cross_val_score
scores = cross_val_score(rf_classifier, x, y, cv=5)
print("Cross-validation accuracy:", scores.mean())

accuracy = accuracy_score(y_test, y_pred)
print ()
print(f'Accuracy: {accuracy}')
print ()
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)


for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):
    print(f"Class {v}:")
    print(f"Precision: {precision[i]}")
    print(f"Recall: {recall[i]}")
    print(f"F1 Score: {f1_score[i]}")
    print()

#Xgboost
import xgboost as xgb
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
xgb_classifier = xgb.XGBClassifier(Objective='multi:softmax',num_class=4)
y=df_encoded['Approved_Flag']
x=df_encoded.drop(['Approved_Flag'],axis=1)
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
xgb_classifier.fit(x_train, y_train)
y_pred = xgb_classifier.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
print ()
print(f'Accuracy: {accuracy:.2f}')
print ()

precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)

for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):
    print(f"Class {v}:")
    print(f"Precision: {precision[i]}")
    print(f"Recall: {recall[i]}")
    print(f"F1 Score: {f1_score[i]}")
    print()

#Hyperparameter tuning for xgboost

#Define the hyperparameter grid
param_grid={
    'colsample_bytree':[0.1,0.3,0.5,0.7,0.9],
    'learning_rate':   [0.001,0.01,0.1,1],
    'max_depth':       [3,5,8,10],
    'alpha':           [1,10,100],
    'n_estimators':    [10,50,100]
}

index=0

answer_grid={
    'combination'     :[],
    'train_Accuracy'  :[],
    'test_Accuracy'   :[],
    'colsample_bytree':[],
    'learning_rate'   :[],
    'max_depth'       :[],
    'alpha'           :[],
    'n_estimators'    :[]
}

#Loop through each combinations of hyperparameters
for colsample_bytree in param_grid['colsample_bytree']:
  for learning_rate in param_grid['learning_rate']:
    for max_depth in param_grid['max_depth']:
      for alpha in param_grid['alpha']:
        for n_estimators in param_grid['n_estimators']:
          index=index+1

          #Define the train the XGBoost model
          model=xgb.XGBClassifier(objective='multi:softmax',
                                  num_class=4,
                                  colsample_bytree=colsample_bytree,
                                  learning_rate=learning_rate,
                                  max_depth=max_depth,
                                  alpha=alpha,
                                  n_estimators=n_estimators)
          y=df_encoded['Approved_Flag']
          x=df_encoded.drop(['Approved_Flag'],axis=1)
          label_encoder = LabelEncoder()
          y = label_encoder.fit_transform(y)
          x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
          model.fit(x_train,y_train)

          #Predict for training and testing sets
          y_pred_train=model.predict(x_train)
          y_pred_test=model.predict(x_test)

          #Calculate accuracy
          train_accuracy=accuracy_score(y_train,y_pred_train)
          test_accuracy=accuracy_score(y_test,y_pred_test)

          #Include into list
          answer_grid['combination'].append(index)
          answer_grid['train_Accuracy'].append(train_accuracy)
          answer_grid['test_Accuracy'].append(test_accuracy)
          answer_grid['colsample_bytree'].append(colsample_bytree)
          answer_grid['learning_rate'].append(learning_rate)
          answer_grid['max_depth'].append(max_depth)
          answer_grid['alpha'].append(alpha)
          answer_grid['n_estimators'].append(n_estimators)

          #Print result for combinations
          print(f"Combination {index}:")
          print(f"colsample_bytree :{colsample_bytree},learning_rate :{learning_rate},max_depth :{max_depth},alpha :{alpha},n_estimators :{n_estimators}")
          print(f"Train Accuracy: {train_accuracy}")
          print(f"Test Accuracy: {test_accuracy}")
          print()

import pandas as pd

# Convert to DataFrame
results_df = pd.DataFrame(answer_grid)

# Export to CSV
results_df.to_csv("xgboost_hyperparameter_results.csv", index=False)
files.download("xgboost_hyperparameter_results.csv")

# 3. Decision Tree
from sklearn.tree import DecisionTreeClassifier


y = df_encoded['Approved_Flag']
x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)


dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)
dt_model.fit(x_train, y_train)
y_pred = dt_model.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
print ()
print(f"Accuracy: {accuracy:.2f}")
print ()

precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)

for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):
    print(f"Class {v}:")
    print(f"Precision: {precision[i]}")
    print(f"Recall: {recall[i]}")
    print(f"F1 Score: {f1_score[i]}")
    print()

"""##**Lets try RVFL for this data and see the pridicted score**"""



import numpy as np
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from scipy.special import softmax

def sigmoid(x):
  return 1/(1+np.exp(-x))

import numpy as np
from scipy.special import softmax

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

class RVFL:
    def __init__(self, input_dim, hidden_nodes, activation=sigmoid):
        self.input_dim = input_dim
        self.hidden_nodes = hidden_nodes
        self.activation = activation
        self.w = np.random.randn(self.hidden_nodes, self.input_dim)
        self.b = np.random.randn(self.hidden_nodes)

    def fit(self, X, y):
        H = self.activation(np.dot(X, self.w.T) + self.b)
        H_ext = np.concatenate([X, H], axis=1)
        self.beta = np.dot(np.linalg.pinv(H_ext), y)

    def predict(self, X):
        H = self.activation(np.dot(X, self.w.T) + self.b)
        H_ext = np.concatenate([X, H], axis=1)
        y_raw = np.dot(H_ext, self.beta)

        # Handle classification:
        if y_raw.ndim == 1 or y_raw.shape[1] == 1:
            # Binary classification
            return (y_raw > 0.5).astype(int).ravel()
        else:
            # Multi-class classification
            return np.argmax(softmax(y_raw, axis=1), axis=1)

y=df_encoded['Approved_Flag']
x=df_encoded.drop(['Approved_Flag'],axis=1)

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

#Train model
model=RVFL(input_dim=x_train.shape[1],hidden_nodes=10)
model.fit(x_train,y_train)

y_pred=model.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')